{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "30cb56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def get_label(activity_type, activity_subtype):\n",
    "    return f'{activity_type} - {activity_subtype}'\n",
    "\n",
    "file_dir = '/Users/julius/uni/pdiot/cw3/2023/all/'\n",
    "\n",
    "columns = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "labels = []\n",
    "feature_accel_x = []\n",
    "feature_accel_y = []\n",
    "feature_accel_z = []\n",
    "feature_gyro_x = []\n",
    "feature_gyro_y = []\n",
    "feature_gyro_z = []\n",
    "test_labels = []\n",
    "test_feature_accel_x = []\n",
    "test_feature_accel_y = []\n",
    "test_feature_accel_z = []\n",
    "test_feature_gyro_x = []\n",
    "test_feature_gyro_y = []\n",
    "test_feature_gyro_z = []\n",
    "\n",
    "for filename in os.listdir(file_dir):\n",
    "    match = re.fullmatch('^Respeck_s\\d{7}_(.*)_(.*)_clean_\\d{2}-\\d{2}-\\d{4}_\\d{2}-\\d{2}-\\d{2}.csv$', filename)\n",
    "    \n",
    "    if match:\n",
    "        label = get_label(match.group(1), match.group(2))\n",
    "        \n",
    "        dataframe = pd.read_csv(os.path.join(file_dir, filename))\n",
    "        data = get_data(dataframe)\n",
    "        \n",
    "        for i in range(6):\n",
    "            labels.append(label)\n",
    "            feature_accel_x.append(dataframe[i * 100:(i + 1) * 100]['accel_x'].values.astype('float32'))\n",
    "            feature_accel_y.append(dataframe[i * 100:(i + 1) * 100]['accel_y'].values.astype('float32'))\n",
    "            feature_accel_z.append(dataframe[i * 100:(i + 1) * 100]['accel_z'].values.astype('float32'))\n",
    "            feature_gyro_x.append(dataframe[i * 100:(i + 1) * 100]['gyro_x'].values.astype('float32'))\n",
    "            feature_gyro_y.append(dataframe[i * 100:(i + 1) * 100]['gyro_y'].values.astype('float32'))\n",
    "            feature_gyro_z.append(dataframe[i * 100:(i + 1) * 100]['gyro_z'].values.astype('float32'))\n",
    "            \n",
    "        test_feature_accel_x.append(dataframe[600:700]['accel_x'].values.astype('float32'))\n",
    "        test_feature_accel_y.append(dataframe[600:700]['accel_y'].values.astype('float32'))\n",
    "        test_feature_accel_z.append(dataframe[600:700]['accel_z'].values.astype('float32'))\n",
    "        test_feature_gyro_x.append(dataframe[600:700]['gyro_x'].values.astype('float32'))\n",
    "        test_feature_gyro_y.append(dataframe[600:700]['gyro_y'].values.astype('float32'))\n",
    "        test_feature_gyro_z.append(dataframe[600:700]['gyro_z'].values.astype('float32'))\n",
    "        test_labels.append(label)\n",
    "\n",
    "int_label_dict = dict(enumerate(set(labels)))\n",
    "label_int_dict = dict([(label, index) for index, label in enumerate(set(labels))])\n",
    "\n",
    "test_labels = np.array([label_int_dict[label] for label in test_labels])\n",
    "\n",
    "labels = np.array([label_int_dict[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "83d67937",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_accel_x = np.array(feature_accel_x)\n",
    "feature_accel_y = np.array(feature_accel_y)\n",
    "feature_accel_z = np.array(feature_accel_z)\n",
    "feature_gyro_x = np.array(feature_gyro_x)\n",
    "feature_gyro_y = np.array(feature_gyro_y)\n",
    "feature_gyro_z = np.array(feature_gyro_z)\n",
    "test_feature_accel_x = np.array(test_feature_accel_x)\n",
    "test_feature_accel_y = np.array(test_feature_accel_y)\n",
    "test_feature_accel_z = np.array(test_feature_accel_z)\n",
    "test_feature_gyro_x = np.array(test_feature_gyro_x)\n",
    "test_feature_gyro_y = np.array(test_feature_gyro_y)\n",
    "test_feature_gyro_z = np.array(test_feature_gyro_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b5297879",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = layers.Input(shape=(100,))\n",
    "input2 = layers.Input(shape=(100,))\n",
    "input3 = layers.Input(shape=(100,))\n",
    "input4 = layers.Input(shape=(100,))\n",
    "input5 = layers.Input(shape=(100,))\n",
    "input6 = layers.Input(shape=(100,))\n",
    "merged = layers.Concatenate(axis=1)([input1, input2, input3, input4, input5, input6])\n",
    "dense1 = layers.Dense(96, input_dim=6, activation='sigmoid', use_bias=True)(merged)\n",
    "output = layers.Dense(44, activation='relu', use_bias=True)(dense1)\n",
    "m = models.Model(inputs=[input1, input2, input3, input4, input5, input6], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b575633c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_152 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_153 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_154 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_155 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_156 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " input_157 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_20 (Concatenate)   (None, 600)          0           ['input_152[0][0]',              \n",
      "                                                                  'input_153[0][0]',              \n",
      "                                                                  'input_154[0][0]',              \n",
      "                                                                  'input_155[0][0]',              \n",
      "                                                                  'input_156[0][0]',              \n",
      "                                                                  'input_157[0][0]']              \n",
      "                                                                                                  \n",
      " dense_101 (Dense)              (None, 96)           57696       ['concatenate_20[0][0]']         \n",
      "                                                                                                  \n",
      " dense_102 (Dense)              (None, 44)           4268        ['dense_101[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 61,964\n",
      "Trainable params: 61,964\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9a673fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['mae'],\n",
    "    loss='mse',\n",
    "    #loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "f08e5e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7bd179a9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7bd179a9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7f7bd179a9e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "614/633 [============================>.] - ETA: 0s - loss: 307.4849 - mae: 14.0235WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7bceeffe60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7bceeffe60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7f7bceeffe60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "633/633 [==============================] - 3s 3ms/step - loss: 305.2054 - mae: 13.9424 - val_loss: 202.7047 - val_mae: 11.7523\n",
      "Epoch 2/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 155.0770 - mae: 10.1804 - val_loss: 199.3684 - val_mae: 11.5855\n",
      "Epoch 3/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 136.3420 - mae: 9.4895 - val_loss: 199.3642 - val_mae: 11.5257\n",
      "Epoch 4/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 123.0550 - mae: 8.9829 - val_loss: 187.4279 - val_mae: 11.1611\n",
      "Epoch 5/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 115.2766 - mae: 8.6577 - val_loss: 200.0402 - val_mae: 11.6462\n",
      "Epoch 6/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 107.5054 - mae: 8.2751 - val_loss: 192.8742 - val_mae: 11.3863\n",
      "Epoch 7/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 102.2517 - mae: 7.9265 - val_loss: 197.9334 - val_mae: 11.7180\n",
      "Epoch 8/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 96.2821 - mae: 7.6515 - val_loss: 193.6661 - val_mae: 11.5768\n",
      "Epoch 9/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 92.3539 - mae: 7.4084 - val_loss: 205.7118 - val_mae: 11.8381\n",
      "Epoch 10/10\n",
      "633/633 [==============================] - 2s 3ms/step - loss: 88.7181 - mae: 7.2056 - val_loss: 205.6869 - val_mae: 11.8619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bbdd92dd0>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(x=[feature_accel_x, feature_accel_y, feature_accel_z, feature_gyro_x, feature_gyro_y, feature_gyro_z], y=labels, batch_size=1, validation_split=0.2, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c71818b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 172.8929 - mae: 10.7972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 172.8929443359375, 'mae': 10.797218322753906}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.evaluate(x=[test_feature_accel_x, test_feature_accel_y, test_feature_accel_z, test_feature_gyro_x, test_feature_gyro_y, test_feature_gyro_z], y=test_labels, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a6e6c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/Users/julius/uni/pdiot/cw3/2023/s2604021/Respeck_s2604021_Descending stairs_Normal_clean_02-10-2023_14-57-44.csv\"\n",
    "\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "accel_x = dataframe[400:500]['accel_x'].values.astype('float32')\n",
    "accel_y = dataframe[400:500]['accel_y'].values.astype('float32')\n",
    "accel_z = dataframe[400:500]['accel_z'].values.astype('float32')\n",
    "gyro_x = dataframe[400:500]['gyro_x'].values.astype('float32')\n",
    "gyro_y = dataframe[400:500]['gyro_y'].values.astype('float32')\n",
    "gyro_z = dataframe[400:500]['gyro_z'].values.astype('float32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "36d71c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = [\n",
    "    np.expand_dims(accel_x, axis=0),\n",
    "    np.expand_dims(accel_y, axis=0),\n",
    "    np.expand_dims(accel_z, axis=0),\n",
    "    np.expand_dims(gyro_x, axis=0),\n",
    "    np.expand_dims(gyro_y, axis=0),\n",
    "    np.expand_dims(gyro_z, axis=0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ee984ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    }
   ],
   "source": [
    "p = m.predict(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "f207151e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[18.618546, 18.743603, 18.679111, 18.71624 , 18.13827 , 18.630268,\n",
       "        18.984854, 18.651892, 18.784233, 18.479322, 19.279171, 19.715895,\n",
       "        18.941048, 18.918516, 19.08693 , 18.875355, 18.8701  , 18.811092,\n",
       "        18.792288, 18.594885, 19.136677, 18.706364, 18.778086, 19.130554,\n",
       "        18.853632, 19.087702, 18.745512, 18.681536, 18.894423, 18.686249,\n",
       "        18.407085, 18.38813 , 18.452389, 18.989107, 18.58169 ,  0.      ,\n",
       "        18.632214, 18.757702, 18.556604, 18.485228, 18.335081, 18.790718,\n",
       "        18.199078, 18.739573]], dtype=float32)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "bc12209e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Normal walking - Normal'"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_label_dict[np.argmax(p[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "c04e23fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f7bcab16f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f7bcab16f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f7bcab16f80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f7bb435e320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f7bb435e320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7f7bb435e320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/b6/ldk_ls6j78l1yw3kdcf9_tgw0000gn/T/tmp6wvg79sb/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/b6/ldk_ls6j78l1yw3kdcf9_tgw0000gn/T/tmp6wvg79sb/assets\n",
      "2023-10-17 23:41:31.642508: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2023-10-17 23:41:31.643419: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2023-10-17 23:41:31.646746: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/b6/ldk_ls6j78l1yw3kdcf9_tgw0000gn/T/tmp6wvg79sb\n",
      "2023-10-17 23:41:31.651137: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-10-17 23:41:31.651184: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /var/folders/b6/ldk_ls6j78l1yw3kdcf9_tgw0000gn/T/tmp6wvg79sb\n",
      "2023-10-17 23:41:31.664041: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2023-10-17 23:41:31.784085: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /var/folders/b6/ldk_ls6j78l1yw3kdcf9_tgw0000gn/T/tmp6wvg79sb\n",
      "2023-10-17 23:41:31.805174: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 158451 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(m)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "model_file = '/Users/julius/uni/pdiot/cw3/model6features.tflite'\n",
    "# Save the model.\n",
    "with open(model_file, 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "8a5f2729",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = '/Users/julius/uni/pdiot/cw3/labels.txt'\n",
    "with open(label_file, 'w') as f:\n",
    "    f.write(str(int_label_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
